{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unicode_translation.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
      "sample_submission.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
      "train.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
      "test_images.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
      "train_images.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c kuzushiji-recognition -p raw\n",
    "\n",
    "!unzip -n -q raw/train.csv.zip -d data\n",
    "!chmod 444 data/train.csv \n",
    "!unzip -n -q raw/train_images.zip -d data/train_images\n",
    "!unzip -n -q raw/test_images.zip -d data/test_images\n",
    "\n",
    "!cp -f raw/unicode_translation.csv data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in /Users/nicholasmi/anaconda3/lib/python3.6/site-packages (3.2)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.2, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "NotoSansCJKjp-hinte 100%[===================>] 115.49M  37.0MB/s    in 3.1s    \n"
     ]
    }
   ],
   "source": [
    "!pip install wget\n",
    "!wget -nd -q --show-progress https://noto-website-2.storage.googleapis.com/pkgs/NotoSansCJKjp-hinted.zip -P raw\n",
    "!unzip -n -q raw/NotoSansCJKjp-hinted.zip -d assets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm_notebook\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'data'\n",
    "\n",
    "# font_path = 'assets/NotoSansCJKjp-Regular.otf'\n",
    "# prop = font_manager.FontProperties(fname=font_path)\n",
    "\n",
    "with open('data/unicode_translation.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader) # skip head  er\n",
    "    unicode = dict(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_to_path(input_id, dir_type='train'):\n",
    "    \"\"\"\n",
    "    Takes an id for a page as an input, and returns the filepath to the image\n",
    "    \"\"\"\n",
    "    path = input_dir + '/' + dir_type + '_images/' + input_id\n",
    "    if '.jpg' not in path:\n",
    "        path = path + '.jpg'\n",
    "        \n",
    "    return path\n",
    "\n",
    "def page_to_bw(*args, **kwargs):\n",
    "    \"\"\"\n",
    "    Takes an id as an input and returns a black and white version of the iamge\n",
    "    \"\"\"\n",
    "    path = id_to_path(*args, **kwargs)    \n",
    "    \n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    (thresh, img_bw) = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    img_bw = cv2.bitwise_not(img_bw)\n",
    "    \n",
    "    return img_bw\n",
    "\n",
    "def label_explode(l):\n",
    "    \"\"\"\n",
    "    Takes a unsplit string (tuple of unicode character and position) and reutnrs a true tuple\n",
    "    \"\"\"\n",
    "    try:\n",
    "        codename, x, y, w, h = str.split(l)\n",
    "    except TypeError:\n",
    "        print('skipping {}'.format(l))\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        char = unicode[codename]\n",
    "    except KeyError:\n",
    "        try:\n",
    "            char = unicode['U' + codename]\n",
    "        except KeyError:\n",
    "            print('{} not found in unicode lookup, skipping'.format(codename))\n",
    "            return None\n",
    "    \n",
    "    x, y, w, h = int(x), int(y), int(w), int(h)\n",
    "    \n",
    "    return char, codename, x, y, w, h\n",
    "\n",
    "def make_square(img, dim=(28,28)):\n",
    "    \"\"\"\n",
    "    Converts the image into a square and adds padding\n",
    "    \"\"\"\n",
    "    aspect = img.shape\n",
    "    max_aspect = max(aspect)\n",
    "    \n",
    "    if max_aspect % 2 != 0:\n",
    "        max_aspect += 11\n",
    "    else:\n",
    "        max_aspect += 10\n",
    "        \n",
    "    y_growth = (max_aspect - aspect[0])/2\n",
    "    x_growth = max_aspect - aspect[1]\n",
    "    \n",
    "    t, b, l, r = int(np.floor(y_growth/2)), int(np.ceil(y_growth/2)), int(np.floor(x_growth/2)), int(np.ceil(x_growth/2))\n",
    "    \n",
    "    square_img = cv2.copyMakeBorder(img, t, b, l, r, cv2.BORDER_CONSTANT, value=(0,0,0))\n",
    "    square_img = cv2.resize(square_img, dim)\n",
    "    \n",
    "    return square_img\n",
    "\n",
    "def labels_and_images(data_type='train', save=True, output_fp=None):\n",
    "    \"\"\"\n",
    "    returns a tuple of labels and images. if save=true, also returns the filepath of the saved npz file\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(input_dir + '/' + data_type + '.csv')\n",
    "    df['chars'] = df.labels.str.findall(r\"[\\w\\+]{6}[\\s\\d]*\\d\")\n",
    "    \n",
    "    df1 = df[['image_id','chars']].explode('chars').reset_index()\n",
    "    df2 = pd.DataFrame(df1['chars'].str.split(expand=True).values, columns=('unicode', 'x_min', 'y_min', 'width', 'height'))\n",
    "\n",
    "    dfo = pd.concat([df1,df2], axis=1)\n",
    "    nums = ['x_min','y_min','width','height']\n",
    "    for n in nums:\n",
    "        dfo[n] = pd.to_numeric(dfo[n], errors='coerce', downcast='integer')\n",
    "\n",
    "    dfo['x_max'] = dfo.x_min + dfo.width\n",
    "    dfo['y_max'] = dfo.y_min + dfo.height\n",
    "\n",
    "    dfo = dfo.drop(['index'], axis=1).dropna()\n",
    "    \n",
    "    labels = dfo.unicode.to_numpy()\n",
    "    \n",
    "    images = []\n",
    "    for g in tqdm_notebook(dfo.groupby('image_id')):\n",
    "        img = page_to_bw(g[0])\n",
    "        dfg = g[1]\n",
    "\n",
    "        for _, row in dfg.iterrows():\n",
    "            y_min, y_max, x_min, x_max = int(row['y_min']), int(row['y_max']), int(row['x_min']), int(row['x_max'])\n",
    "            images.append(make_square(img[y_min:y_max, x_min:x_max]))\n",
    "\n",
    "    images = np.array(images)\n",
    "    \n",
    "    if save:\n",
    "        if output_fp is None:\n",
    "            output_fp = input_dir + '/' + data_type + '_img_data.npz'\n",
    "        np.savez_compressed(output_fp, labels=labels, images=images)\n",
    "    \n",
    "    return labels, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6731948592dc47fbbc0fbcbc36a58c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3605), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_labels, train_images = labels_and_images('train')\n",
    "train_dir = input_dir + '/train_img_data.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(683464,) (683464, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.shape, train_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create KujuMNIST Dataset class for torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from torchvision.datasets.utils import makedir_exist_ok, download_url\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class KujuMNIST_DS(Dataset):\n",
    "    \n",
    "    def __init__(self, data_fp, num_classes=10, tfms=None, generate_data=False, *args, **kwargs):\n",
    "        if generate_data == True:\n",
    "            self.target, self.data = generate_data(*args, **kwargs)\n",
    "            \n",
    "        else:\n",
    "            npz = np.load(data_fp, allow_pickle=True)\n",
    "            self.data = npz['images']\n",
    "            self.target = npz['labels']\n",
    "            \n",
    "        le = LabelEncoder()\n",
    "        self.target = le.fit_transform(self.target)\n",
    "            \n",
    "        self.c = num_classes\n",
    "        self.tfms = tfms\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        cur_data = np.expand_dims(self.data[index], axis=-1)\n",
    "\n",
    "        if self.tfms:\n",
    "            cur_data = self.tfms(cur_data)\n",
    "        \n",
    "        target = int(self.target[index])\n",
    "        img, target = cur_data, target\n",
    "        \n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_data(*args, **kwargs):\n",
    "        return labels_and_images(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model\n",
    "\n",
    "Extensive credits to https://github.com/ranihorev/Kuzushiji_MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "from torchvision.models.resnet import resnet18, ResNet, BasicBlock\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets.utils import makedir_exist_ok, download_url\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import BatchSampler, DataLoader, random_split\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'data'\n",
    "train_dir = input_dir + '/train_img_data.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.load(train_dir)['images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean = train_images.mean()\n",
    "data_std = train_images.std()\n",
    "\n",
    "default_device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "transform_train = transforms.Compose(\n",
    "    [transforms.ToPILImage(), \n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((data_mean,), (data_std,)),\n",
    "    ])\n",
    "\n",
    "transform_valid = transforms.Compose(\n",
    "    [transforms.ToPILImage(), \n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((data_mean,), (data_std,)),\n",
    "    ])\n",
    "\n",
    "total_ds = KujuMNIST_DS(train_dir, tfms=transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(total_ds))\n",
    "test_size = len(total_ds) - train_size\n",
    "\n",
    "train_ds, test_ds = random_split(total_ds, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=1, pin_memory=True)\n",
    "val_dl = DataLoader(test_ds, batch_size=128, shuffle=True, num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "databunch = DataBunch(train_dl=trn_dl, valid_dl=val_dl, device=default_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4212"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(total_ds.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):  \n",
    "    \"\"\"\n",
    "    Based on - https://github.com/kkweon/mnist-competition\n",
    "    \"\"\"\n",
    "    def two_conv_pool(self, in_channels, f1, f2):\n",
    "        s = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, f1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(f1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(f1, f2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(f2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        for m in s.children():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "        return s\n",
    "    \n",
    "    def three_conv_pool(self,in_channels, f1, f2, f3):\n",
    "        s = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, f1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(f1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(f1, f2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(f2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(f2, f3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(f3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        for m in s.children():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "        return s\n",
    "        \n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super(VGG, self).__init__()\n",
    "        self.l1 = self.two_conv_pool(1, 64, 64)\n",
    "        self.l2 = self.two_conv_pool(64, 128, 128)\n",
    "        self.l3 = self.three_conv_pool(128, 256, 256, 256)\n",
    "        self.l4 = self.three_conv_pool(256, 256, 256, 256)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p = 0.5),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p = 0.5),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.l3(x)\n",
    "        x = self.l4(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return F.log_softmax(x, dim=1) \n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    \n",
    "class MyResNet(nn.Module):\n",
    "    # Based on PyTorch ResNet-18\n",
    "    \n",
    "    def __init__(self, block, layers, num_classes=len(set(total_ds.target)), zero_init_residual=False):\n",
    "        super(MyResNet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "                    \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p = 0.5),\n",
    "            nn.Linear(512 * block.expansion, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p = 0.5),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         import pdb; pdb.set_trace()\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "class VGG_ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG_ResNet, self).__init__()\n",
    "        self.vgg = VGG(len(set(total_ds.target)))\n",
    "        self.resnet = MyResNet(BasicBlock, [2, 2, 2, 2])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        vgg_out = self.vgg(x)\n",
    "        resnet_out = self.resnet(x)\n",
    "        out = (vgg_out + resnet_out) / 2\n",
    "        return out\n",
    "    \n",
    "def vgg_resnet_load_model(learner, vgg_name, resnet_name):\n",
    "        device = learner.data.device\n",
    "        vgg_state = torch.load(learner.path/learner.model_dir/f'{vgg_name}.pth', map_location=device)\n",
    "        learner.model.vgg.load_state_dict(vgg_state['model'], strict=True)\n",
    "        \n",
    "        resnet_state = torch.load(learner.path/learner.model_dir/f'{resnet_name}.pth', map_location=device)\n",
    "        learner.model.resnet.load_state_dict(resnet_state['model'], strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.910229</td>\n",
       "      <td>673.799683</td>\n",
       "      <td>0.004645</td>\n",
       "      <td>7:43:52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(databunch, VGG_ResNet(), metrics=accuracy)\n",
    "learn.fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
